--- a/datapath/datapath.c
+++ b/datapath/datapath.c
@@ -304,6 +304,133 @@ out:
 	u64_stats_update_end(&stats->syncp);
 }
 
+static struct net_device *ovs_flow_get_single_dest(struct sw_flow *flow, struct datapath *dp)
+{
+	struct sw_flow_actions *sf_acts;
+	const struct nlattr *a;
+	struct vport *vport = NULL;
+	int rem;
+	int port_no = -1;
+
+	sf_acts = rcu_dereference(flow->sf_acts);
+
+	for (a = sf_acts->actions, rem = sf_acts->actions_len; rem > 0;
+	     a = nla_next(a, &rem)) {
+		if(nla_type(a) == OVS_ACTION_ATTR_OUTPUT) {
+			if(port_no == -1)
+				port_no = nla_get_u32(a);
+			else { //flow are not learned, and there are multiple dest
+				port_no = -1;
+				break;
+			}
+		}
+	}
+
+	if(port_no != -1) {
+		vport = ovs_lookup_vport(dp, port_no);
+
+		if (vport)
+			return vport->dev;
+	}
+
+	return NULL;
+}
+
+static struct net_device *ovs_flow_find_src_dev(struct datapath *dp, char *src_mac, struct net_device *dst_dev)
+{
+	struct table_instance *ti;
+	struct sw_flow_key *key;
+	struct sw_flow *flow;
+	struct vport *in_vport = NULL;
+	struct vport *act_vport = NULL;
+	struct net_device *dev = NULL;
+	struct sw_flow_actions *sf_acts;
+	const struct nlattr *a;
+	int rem;
+	int i;
+	int ver;
+	int in_port;
+	int act_port;
+
+	ti = rcu_dereference(dp->table.ti);
+
+	ver = ti->node_ver;
+	for (i = 0; i < ti->n_buckets; i++) {
+		struct hlist_head *head;
+
+		head = flex_array_get(ti->buckets, i);
+
+		hlist_for_each_entry(flow, head, flow_table.node[ver]) {
+			key = &flow->key;
+
+			if (!memcmp(key->eth.src, src_mac, ETH_ALEN) && !memcmp(key->eth.dst, dst_dev->dev_addr, ETH_ALEN)) {
+				sf_acts = rcu_dereference(flow->sf_acts);
+
+				for (a = sf_acts->actions, rem = sf_acts->actions_len; rem > 0;
+					 a = nla_next(a, &rem)) {
+					if(nla_type(a) == OVS_ACTION_ATTR_OUTPUT) {
+						act_port = nla_get_u32(a);
+						act_vport = ovs_lookup_vport(dp, act_port);
+						if (act_vport->dev == dst_dev) {
+							in_port = key->phy.in_port;
+							in_vport = ovs_lookup_vport(dp, in_port);
+							dev = in_vport->dev;
+							goto done;
+						}
+					}
+				}
+			}
+		}
+	}
+
+done:
+	return dev;
+}
+
+struct net_device *ovs_port_dev_get(struct net_device *src_dev, char *dst_mac, int ip_version, struct sk_buff *skb)
+{
+	struct net_device *dest_dev = NULL;
+	struct datapath *dp;
+	struct vport *src_vport = NULL;
+	struct sw_flow *flow = NULL;
+	struct sw_flow_key key;
+
+	src_vport = ovs_internal_dev_get_vport(src_dev);
+	if (!src_vport)
+		return NULL;
+
+	dp = src_vport->dp;
+	if (!dp)
+		return NULL;
+
+	memset(&key, 0, sizeof(struct sw_flow_key));
+	key.phy.in_port = src_vport->port_no;
+	key.eth.type = ip_version == 4 ? htons(ETH_P_IP) : htons(ETH_P_IPV6);
+	memcpy(key.eth.src, src_dev->dev_addr, ETH_ALEN);
+	memcpy(key.eth.dst, dst_mac, ETH_ALEN);
+
+	flow = ovs_flow_tbl_lookup(&dp->table, &key);
+
+	if (flow)
+		dest_dev = ovs_flow_get_single_dest(flow, dp);
+
+	if (!dest_dev) {
+		key.eth.type = htons(ETH_P_ARP);
+		flow = ovs_flow_tbl_lookup(&dp->table, &key);
+		if (flow)
+			dest_dev = ovs_flow_get_single_dest(flow, dp);
+	}
+
+	if (!dest_dev)
+		dest_dev = ovs_flow_find_src_dev(dp, dst_mac, src_dev);
+
+	if (dest_dev && skb)
+		ovs_flow_stats_update(flow, 0, skb);
+
+	return dest_dev;
+}
+EXPORT_SYMBOL(ovs_port_dev_get);
+
 int ovs_dp_upcall(struct datapath *dp, struct sk_buff *skb,
 		  const struct sw_flow_key *key,
 		  const struct dp_upcall_info *upcall_info,
--- a/datapath/vport-internal_dev.c
+++ b/datapath/vport-internal_dev.c
@@ -299,6 +299,7 @@ int ovs_is_internal_dev(const struct net
 {
 	return netdev->netdev_ops == &internal_dev_netdev_ops;
 }
+EXPORT_SYMBOL(ovs_is_internal_dev);
 
 struct vport *ovs_internal_dev_get_vport(struct net_device *netdev)
 {
